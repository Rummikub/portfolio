{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import transformers\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: datasets in c:\\users\\dotto\\anaconda3\\lib\\site-packages (2.14.4)\n",
      "Requirement already satisfied: transformers in c:\\users\\dotto\\anaconda3\\lib\\site-packages (4.31.0)\n",
      "Requirement already satisfied: aiohttp in c:\\users\\dotto\\anaconda3\\lib\\site-packages (from datasets) (3.8.5)\n",
      "Requirement already satisfied: pyarrow>=8.0.0 in c:\\users\\dotto\\anaconda3\\lib\\site-packages (from datasets) (12.0.1)\n",
      "Requirement already satisfied: multiprocess in c:\\users\\dotto\\anaconda3\\lib\\site-packages (from datasets) (0.70.15)\n",
      "Requirement already satisfied: requests>=2.19.0 in c:\\users\\dotto\\anaconda3\\lib\\site-packages (from datasets) (2.26.0)\n",
      "Requirement already satisfied: xxhash in c:\\users\\dotto\\anaconda3\\lib\\site-packages (from datasets) (3.3.0)\n",
      "Requirement already satisfied: huggingface-hub<1.0.0,>=0.14.0 in c:\\users\\dotto\\anaconda3\\lib\\site-packages (from datasets) (0.16.4)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\dotto\\anaconda3\\lib\\site-packages (from datasets) (6.0)\n",
      "Requirement already satisfied: tqdm>=4.62.1 in c:\\users\\dotto\\anaconda3\\lib\\site-packages (from datasets) (4.62.3)\n",
      "Requirement already satisfied: packaging in c:\\users\\dotto\\anaconda3\\lib\\site-packages (from datasets) (21.0)\n",
      "Requirement already satisfied: fsspec[http]>=2021.11.1 in c:\\users\\dotto\\anaconda3\\lib\\site-packages (from datasets) (2023.6.0)\n",
      "Requirement already satisfied: dill<0.3.8,>=0.3.0 in c:\\users\\dotto\\anaconda3\\lib\\site-packages (from datasets) (0.3.7)\n",
      "Requirement already satisfied: numpy>=1.17 in c:\\users\\dotto\\anaconda3\\lib\\site-packages (from datasets) (1.26.1)\n",
      "Requirement already satisfied: pandas in c:\\users\\dotto\\anaconda3\\lib\\site-packages (from datasets) (1.3.4)\n",
      "Requirement already satisfied: regex!=2019.12.17 in c:\\users\\dotto\\anaconda3\\lib\\site-packages (from transformers) (2021.8.3)\n",
      "Requirement already satisfied: safetensors>=0.3.1 in c:\\users\\dotto\\anaconda3\\lib\\site-packages (from transformers) (0.3.2)\n",
      "Requirement already satisfied: filelock in c:\\users\\dotto\\anaconda3\\lib\\site-packages (from transformers) (3.3.1)\n",
      "Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in c:\\users\\dotto\\anaconda3\\lib\\site-packages (from transformers) (0.13.3)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in c:\\users\\dotto\\anaconda3\\lib\\site-packages (from aiohttp->datasets) (1.3.1)\n",
      "Requirement already satisfied: charset-normalizer<4.0,>=2.0 in c:\\users\\dotto\\anaconda3\\lib\\site-packages (from aiohttp->datasets) (2.0.4)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in c:\\users\\dotto\\anaconda3\\lib\\site-packages (from aiohttp->datasets) (1.4.0)\n",
      "Requirement already satisfied: attrs>=17.3.0 in c:\\users\\dotto\\anaconda3\\lib\\site-packages (from aiohttp->datasets) (21.2.0)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in c:\\users\\dotto\\anaconda3\\lib\\site-packages (from aiohttp->datasets) (4.0.3)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in c:\\users\\dotto\\anaconda3\\lib\\site-packages (from aiohttp->datasets) (6.0.4)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in c:\\users\\dotto\\anaconda3\\lib\\site-packages (from aiohttp->datasets) (1.9.2)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\dotto\\anaconda3\\lib\\site-packages (from huggingface-hub<1.0.0,>=0.14.0->datasets) (4.8.0)\n",
      "Requirement already satisfied: pyparsing>=2.0.2 in c:\\users\\dotto\\anaconda3\\lib\\site-packages (from packaging->datasets) (3.0.4)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\dotto\\anaconda3\\lib\\site-packages (from requests>=2.19.0->datasets) (1.26.7)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\dotto\\anaconda3\\lib\\site-packages (from requests>=2.19.0->datasets) (2021.10.8)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\dotto\\anaconda3\\lib\\site-packages (from requests>=2.19.0->datasets) (2.10)\n",
      "Requirement already satisfied: colorama in c:\\users\\dotto\\anaconda3\\lib\\site-packages (from tqdm>=4.62.1->datasets) (0.4.4)\n",
      "Requirement already satisfied: pytz>=2017.3 in c:\\users\\dotto\\anaconda3\\lib\\site-packages (from pandas->datasets) (2021.3)\n",
      "Requirement already satisfied: python-dateutil>=2.7.3 in c:\\users\\dotto\\anaconda3\\lib\\site-packages (from pandas->datasets) (2.8.2)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\dotto\\anaconda3\\lib\\site-packages (from python-dateutil>=2.7.3->pandas->datasets) (1.16.0)\n"
     ]
    }
   ],
   "source": [
    "! pip install datasets transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.31.0\n"
     ]
    }
   ],
   "source": [
    "import transformers\n",
    "print(transformers.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0136b088ff644e108db2be0e5a7ab0f5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HTML(value='<center> <img\\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.sv…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from huggingface_hub import notebook_login\n",
    "notebook_login()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers.utils import send_example_telemetry\n",
    "\n",
    "send_example_telemetry(\"language_modeling_notebook\", framework=\"pytorch\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "datasets = load_dataset('text', data_files={'train': \"../data/train_data.txt\", 'validation': \"../data/test_data.txt\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'text': \"customer: Hi, is this jacket dry clean only? agent: Hello, it is not dry clean only. We use high quality fabric in our materials, so you can wash and dry them in a typical washer and dryer! customer: Great! It is a little inconvenient when one is not machine washable. agent: I highly agree! Especially with everything happening right now, you may not even be able to find one that is open! agent: Anyway, is there anything else I can help you with? customer: Do they come in different colors agent: Hello, I would have to direct you to our website, as our stock is very dynamic. If you do not see the color you like, I suggest checking back at the end of the month, when we refill the stock customer: That's alright. I actually want it in red if you have it. But if not, I'll get this. agent: That sounds great! Is there anything else I can help you with? customer: this is good. thank you agent: Have a great day!\"}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "datasets['train'][10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import ClassLabel\n",
    "import random\n",
    "from IPython.display import display,HTML\n",
    "\n",
    "def show_random_elements(dataset, num_examples=10):\n",
    "    assert num_examples <= len(dataset), \"Can't pick more\"\n",
    "    picks=[]\n",
    "    for _ in range(num_examples):\n",
    "        pick = random.randint(0, len(dataset)-1)\n",
    "        while pick in picks:\n",
    "            pick = random.randint(0,len(dataset)-1)\n",
    "        picks.append(pick)\n",
    "        \n",
    "    df = pd.DataFrame(dataset[picks])\n",
    "    for column, typ in dataset.features.items():\n",
    "        if isinstance(typ, ClassLabel):\n",
    "            df[column] = df[column].transform(lambda i: typ.names[i])\n",
    "    display(HTML(df.to_html()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>agent: AcmeBrands, how may I help you? customer: I think I may have a subscription that I didn't order agent: Let me help you with that. agent: Could I have your full name or account id? customer: Rodriguez Domingo agent: How did you hear about that subscription? customer: I heard some news about it agent: Let me check the system. agent: There is a subscription on your account. agent: Let me remove it from your account. customer: okay, thanks customer: cool, will I get a refund? agent: That subscription has been removed from your account. agent: How much was the subscription, so that I can refund the amount? customer: It should be $40 customer: great, thanks agent: I apologize for the error. Your refund should be in your account. agent: Can I help you with anything else? customer: cool, thanks, that's all agent: Have a good day.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>agent: Hi, how are you doing today? customer: I got an email that seemed to display a different item than I ordered customer: can you confirm that the item being delivered is michael kors boots? agent: Sure, I can look into that for you. agent: What is your name? customer: Chloe Zhang agent: Thank you, can I also have your account ID and order ID agent: Along with those two items, I will also need your username and email address please customer: czhang99 czhang99@email.com agent: Can I also have your account ID and order ID? customer: FBPJ0UKPVS 2970875983 agent: Thank you, one moment while I check the system please agent: I apologize, it looks like the email was correct. I will change the order in our system to the Michael Kors boots for you. customer: thanks agent: You're welcome, is there anything else I can help you with today? customer: no that was all agent: Have a great day!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>customer: hello? agent: Hello, how can I help you? customer: Yes, I want to check on the status of my premium subscription shopping service.  Do I need to make a payment before it is activated? agent: Let me check that for you, can I have your full name, account ID, and order ID/ customer: Joseph Banter customer: Account ID: NJ8N9YQDWP customer: Order ID: 0020283275 agent: Your subscription is already active, but it will be deactivated tomorrow if you do not make a payment by tomorrow. customer: ok, how much do i owe? agent: Your fee is $55, I will send you a link that shows this information to you next time. All you need is your username. customer: ok great.  thank you agent: You're welcome, is there anything else you need? customer: nope, that covers it.  thanks agent: Okay, thank you and have a nice day.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>agent: Hello. How may I help you today? customer: I'm looking at these Calvin Klein boots.  Are the laces Brown or Black? agent: One moment while I look into this for you please. agent: Most of our boots have blacks laces. About 90% of them. agent: You can see on the product page what color they are. agent: Does that answer your  question? agent: Is there anything else I can help you with? agent: Have a great day.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>agent: How can I help you? customer: Hello, I am trying to browse the site and it is going really slow for me agent: Sorry to hear that. Can you please try refreshing? customer: I tried that and did not work agent: I'm sorry try to log out and back in is what I mean. customer: I did that as well agent: I can file a report with our website team so they can look into it. customer: Ok that would be great agent: Can you please closing out all other tabs, that will sometimes slow things down. customer: That seemed to work for me, thank you for the help agent: You're welcome. Can I help with anything else? customer: That is all</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>agent: Hello, thank you for contacting AcmeCorp how may I help you? customer: I am expecting a $84 refund and just wanted to check on the status of that refund agent: I would happy to look into this for you. agent: May I have your full name or Account ID please? customer: David Williams agent: Thank you David, may I please have your username, email address, and Order ID? customer: Username: davidw06 customer: Email Address: davidw06@email.com customer: Order ID: 8957811624 agent: Your refund is in progress, looks like it was done online. You should receive in next 2 to 3 business days. customer: Ok.  Thank you agent: Is there anything else I may help you with today? customer: Nope that is all agent: Thank you for contacting AcmeCorp, you have a great day.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>customer: hi i love these calvin klein jeans agent: Hi. Thanks for contacting the customer support team, how may I help you today? customer: i want to know if there are any smaller sizes? customer: the ones seem huge! agent: They are kind of awesome. Let me check into that for you. agent: Can I please get your name? customer: Alessandro Phoenix agent: They come in a large variety of widths and the inseam is a standard 36 inches. agent: If they are out of stock on the site, that means we don't have any left. agent: But you can always check back at the beginning of the month when we restock. agent: Does that answer all of your questions about the jeans? customer: tht does ! customer: thanks agent: Is there anything else that I can help with today? agent: Have a tremendous day!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>agent: Hello. Can I be of any assistance? customer: I want to change the address in my account agent: I see. Can I have your name or account ID please? agent: Hello? customer: Joseph Banter agent: Can you provide me with your current address? customer: 8044 Woodshore St Monterey, MI 51929 agent: Can you provide me with your phone number,  PIN, and username? customer: PIN : 778228 UserName: jb145369 agent: Thanks Joseph. agent: What will be the new address? customer: just the street number was wrong the new one is 8045 agent: Alright Joseph I got everything updated for you. customer: thank you for your help agent: You are welcome. Good bye.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>agent: Hi, how can I help you? customer: I want to know more about  a product agent: Okay, which product are you interested in? customer: I want to know how to wash a Michael Kors Jacket agent: You can use a normal washer and dryer, but we suggest keeping the dryer on low heat. customer: Okay. Thanks agent: Do you have any other questions for me? customer: No agent: Okay, have a great day!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>agent: Hi, How can I help you today? customer: I've been trying to buy something, but it keeps saying my credit card is invalid. agent: I see, just a moment please agent: Did you try to re enter the information? customer: I tried several times. agent: I see, have you tried logging out then in of the account? agent: Are you there? customer: Yes, I have tried logging out. agent: Ah, it did not do anything? customer: No, it still says my card is invalid. agent: I see, have you checked the expiration date on the card?  It might be too old. customer: No, I haven't checked that. I'll look and see. customer: Yes, it was expired. I'm sorry - I'll use a different card. agent: Ah ha! There we go. Is there anything else I can help you with today? customer: No, that was all! agent: Great, we appreciate your business at AcmeCorp and have a good day! customer: You too!</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_random_elements(datasets['train'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_checkpoint='gpt2'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using pad_token, but it is not set yet.\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_checkpoint, use_fast=True)\n",
    "if tokenizer.pad_token is None:\n",
    "    tokenizer.add_special_tokens({'pad_token':'[PAD]'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize_function(examples,tokenizer=tokenizer):\n",
    "    return tokenizer(examples['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map (num_proc=4): 100%|██████████| 8034/8034 [00:09<00:00, 822.23 examples/s] \n",
      "Map (num_proc=4): 100%|██████████| 1004/1004 [00:07<00:00, 133.62 examples/s]\n"
     ]
    }
   ],
   "source": [
    "tokenized_datasets= datasets.map(tokenize_function, batched=True, num_proc=4, remove_columns=['text'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': [25781,\n",
       "  25,\n",
       "  922,\n",
       "  6672,\n",
       "  11,\n",
       "  703,\n",
       "  460,\n",
       "  314,\n",
       "  1037,\n",
       "  345,\n",
       "  30,\n",
       "  6491,\n",
       "  25,\n",
       "  655,\n",
       "  2227,\n",
       "  284,\n",
       "  2198,\n",
       "  319,\n",
       "  262,\n",
       "  3722,\n",
       "  286,\n",
       "  257,\n",
       "  12929,\n",
       "  5797,\n",
       "  25,\n",
       "  1654,\n",
       "  11,\n",
       "  561,\n",
       "  345,\n",
       "  1577,\n",
       "  502,\n",
       "  534,\n",
       "  1336,\n",
       "  1438,\n",
       "  393,\n",
       "  1848,\n",
       "  4522,\n",
       "  6491,\n",
       "  25,\n",
       "  47319,\n",
       "  28092,\n",
       "  9643,\n",
       "  6491,\n",
       "  25,\n",
       "  49812,\n",
       "  8538,\n",
       "  24,\n",
       "  2670,\n",
       "  5797,\n",
       "  25,\n",
       "  3224,\n",
       "  284,\n",
       "  428,\n",
       "  345,\n",
       "  561,\n",
       "  1577,\n",
       "  502,\n",
       "  262,\n",
       "  1502,\n",
       "  4522,\n",
       "  290,\n",
       "  3053,\n",
       "  5797,\n",
       "  25,\n",
       "  3387,\n",
       "  6491,\n",
       "  25,\n",
       "  9225,\n",
       "  1433,\n",
       "  3134,\n",
       "  2414,\n",
       "  1983,\n",
       "  6491,\n",
       "  25,\n",
       "  49812,\n",
       "  8538,\n",
       "  24,\n",
       "  2670,\n",
       "  31,\n",
       "  12888,\n",
       "  13,\n",
       "  785,\n",
       "  6491,\n",
       "  25,\n",
       "  645,\n",
       "  18572,\n",
       "  5797,\n",
       "  25,\n",
       "  2279,\n",
       "  287,\n",
       "  1502,\n",
       "  11,\n",
       "  2582,\n",
       "  314,\n",
       "  481,\n",
       "  7603,\n",
       "  262,\n",
       "  3722,\n",
       "  286,\n",
       "  534,\n",
       "  12929,\n",
       "  13,\n",
       "  6491,\n",
       "  25,\n",
       "  1049,\n",
       "  6491,\n",
       "  25,\n",
       "  1309,\n",
       "  502,\n",
       "  760,\n",
       "  5797,\n",
       "  25,\n",
       "  632,\n",
       "  318,\n",
       "  3058,\n",
       "  287,\n",
       "  4371,\n",
       "  290,\n",
       "  262,\n",
       "  6074,\n",
       "  2446,\n",
       "  351,\n",
       "  543,\n",
       "  340,\n",
       "  318,\n",
       "  852,\n",
       "  13686,\n",
       "  318,\n",
       "  2691,\n",
       "  3371,\n",
       "  534,\n",
       "  3884,\n",
       "  2657,\n",
       "  13,\n",
       "  6491,\n",
       "  25,\n",
       "  703,\n",
       "  881,\n",
       "  890,\n",
       "  10597,\n",
       "  340,\n",
       "  318,\n",
       "  12929,\n",
       "  276,\n",
       "  5797,\n",
       "  25,\n",
       "  1342,\n",
       "  621,\n",
       "  257,\n",
       "  1285,\n",
       "  6491,\n",
       "  25,\n",
       "  1049,\n",
       "  5176,\n",
       "  329,\n",
       "  534,\n",
       "  1037,\n",
       "  5797,\n",
       "  25,\n",
       "  257,\n",
       "  9476,\n",
       "  284,\n",
       "  1037,\n",
       "  345,\n",
       "  5797,\n",
       "  25,\n",
       "  423,\n",
       "  257,\n",
       "  3621,\n",
       "  1110],\n",
       " 'attention_mask': [1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1]}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenized_datasets['train'][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#block_size=tokenizer.model_max_length #1024\n",
    "block_size=128\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def group_texts(examples, block_size=block_size):\n",
    "    # Concatenate all texts.\n",
    "    concatenated_examples = {k: sum(examples[k], []) for k in examples.keys()}\n",
    "    total_length = len(concatenated_examples[list(examples.keys())[0]])\n",
    "    # We drop the small remainder, we could add padding if the model supported it instead of this drop, you can\n",
    "    # customize this part to your needs.\n",
    "    if total_length >= block_size:\n",
    "        total_length = (total_length // block_size) * block_size\n",
    "    # Split by chunks of block_size.\n",
    "    result = {\n",
    "        k: [t[i : i + block_size] for i in range(0, total_length, block_size)]\n",
    "        for k, t in concatenated_examples.items()\n",
    "    }\n",
    "    result[\"labels\"] = result[\"input_ids\"].copy()\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map (num_proc=4): 100%|██████████| 8034/8034 [00:10<00:00, 762.56 examples/s] \n",
      "Map (num_proc=4): 100%|██████████| 1004/1004 [00:05<00:00, 178.75 examples/s]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "lm_datasets = tokenized_datasets.map(group_texts, batched=True, batch_size=1000,  num_proc=4, )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\" a bronze agent: ok, was the purchase made in the last 90 days? customer: No, I bought it in November. agent: ok, unfortunately because it has been more than 90 days we cannot accept the return. Would there be anything else I can help you with? customer: What if I ask really, really nicely? agent: I can escalate to my manager if you'd like agent: I'd just need your phone number. customer: (977) 625-2661 customer: I'll look forward to hearing from them. customer: Thanks for trying to help. agent: OK, I have let my manager know\""
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.decode(lm_datasets['train'][1]['input_ids'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Training Configuration\n",
    "# Add AutoModelForCasualLM-\n",
    "\n",
    "from transformers import AutoModelForCausalLM\n",
    "model = AutoModelForCausalLM.from_pretrained(model_checkpoint)\n",
    "\n",
    "# Tokenizer is not defined\n",
    "from transformers import Trainer, TrainingArguments\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = model_checkpoint.split(\"/\")[-1]\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=f\"{model_name}-finetuned-wikitext2\",\n",
    "    evaluation_strategy = \"epoch\",\n",
    "    learning_rate=2e-5,\n",
    "    weight_decay=0.01,\n",
    "    push_to_hub=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Cloning https://huggingface.co/yeseok/gpt2-finetuned-wikitext2 into local empty directory.\n"
     ]
    }
   ],
   "source": [
    "# HTTPError\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=lm_datasets['train'],\n",
    "    eval_dataset=lm_datasets['validation'],\n",
    "    tokenizer=tokenizer,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.16.4\n"
     ]
    }
   ],
   "source": [
    "# HTTP Error, RepositoryNotFoundError bug\n",
    "import huggingface_hub\n",
    "print(huggingface_hub.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'GPT2LMHeadModel'"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Model check\n",
    "model.__class__.__name__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\dotto\\anaconda3\\lib\\site-packages\\transformers\\optimization.py:411: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "  0%|          | 0/5283 [00:00<?, ?it/s]You're using a GPT2TokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n",
      "  9%|▉         | 500/5283 [3:04:06<19:43:47, 14.85s/it]   "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 2.5468, 'learning_rate': 1.8107136096914633e-05, 'epoch': 0.28}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 19%|█▉        | 1000/5283 [5:34:38<27:45:03, 23.33s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 2.2647, 'learning_rate': 1.6214272193829265e-05, 'epoch': 0.57}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 28%|██▊       | 1500/5283 [7:59:56<21:27:28, 20.42s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 2.1604, 'learning_rate': 1.4321408290743897e-05, 'epoch': 0.85}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                        \n",
      " 33%|███▎      | 1761/5283 [9:59:35<19:01:07, 19.44s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 2.058198928833008, 'eval_runtime': 1046.7231, 'eval_samples_per_second': 1.681, 'eval_steps_per_second': 0.21, 'epoch': 1.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 38%|███▊      | 2000/5283 [11:18:46<23:08:30, 25.38s/it]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 2.1042, 'learning_rate': 1.2428544387658528e-05, 'epoch': 1.14}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 47%|████▋     | 2500/5283 [15:58:28<18:48:54, 24.34s/it]   "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 2.057, 'learning_rate': 1.0535680484573161e-05, 'epoch': 1.42}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 57%|█████▋    | 3000/5283 [19:53:00<18:51:31, 29.74s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 2.0318, 'learning_rate': 8.642816581487791e-06, 'epoch': 1.7}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 66%|██████▋   | 3500/5283 [27:28:32<10:00:29, 20.21s/it]    "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 2.027, 'learning_rate': 6.749952678402424e-06, 'epoch': 1.99}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \n",
      " 67%|██████▋   | 3522/5283 [27:55:40<10:29:18, 21.44s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 1.9842828512191772, 'eval_runtime': 1026.9433, 'eval_samples_per_second': 1.714, 'eval_steps_per_second': 0.214, 'epoch': 2.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 76%|███████▌  | 4000/5283 [30:46:40<8:12:53, 23.05s/it]   "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 1.9843, 'learning_rate': 4.8570887753170555e-06, 'epoch': 2.27}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 85%|████████▌ | 4500/5283 [33:55:55<4:32:48, 20.90s/it] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 1.9843, 'learning_rate': 2.9642248722316867e-06, 'epoch': 2.56}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 95%|█████████▍| 5000/5283 [36:52:59<1:41:03, 21.43s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 1.9697, 'learning_rate': 1.0713609691463186e-06, 'epoch': 2.84}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                        \n",
      "100%|██████████| 5283/5283 [38:52:44<00:00, 26.49s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 1.9649392366409302, 'eval_runtime': 1031.8592, 'eval_samples_per_second': 1.706, 'eval_steps_per_second': 0.213, 'epoch': 3.0}\n",
      "{'train_runtime': 139964.5478, 'train_samples_per_second': 0.302, 'train_steps_per_second': 0.038, 'train_loss': 2.1058111037355967, 'epoch': 3.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=5283, training_loss=2.1058111037355967, metrics={'train_runtime': 139964.5478, 'train_samples_per_second': 0.302, 'train_steps_per_second': 0.038, 'train_loss': 2.1058111037355967, 'epoch': 3.0})"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train data\n",
    "trainer.train()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Masked language modeling\n",
    "model_checkpoint = \"distilroberta-base\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map (num_proc=4): 100%|██████████| 8034/8034 [00:17<00:00, 469.75 examples/s] \n",
      "Map (num_proc=4): 100%|██████████| 1004/1004 [00:11<00:00, 89.65 examples/s]\n"
     ]
    }
   ],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(model_checkpoint, use_fast=True)\n",
    "tokenized_datasets = datasets.map(tokenize_function, batched=True, num_proc=4, remove_columns='text')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map (num_proc=4): 100%|██████████| 8034/8034 [00:14<00:00, 543.51 examples/s]\n",
      "Map (num_proc=4): 100%|██████████| 1004/1004 [00:05<00:00, 187.35 examples/s]\n"
     ]
    }
   ],
   "source": [
    "lm_datasets = tokenized_datasets.map(\n",
    "    group_texts,\n",
    "    batched=True,\n",
    "    batch_size=1000,\n",
    "    num_proc=4,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at distilroberta-base were not used when initializing RobertaForMaskedLM: ['roberta.pooler.dense.weight', 'roberta.pooler.dense.bias']\n",
      "- This IS expected if you are initializing RobertaForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoModelForMaskedLM\n",
    "model = AutoModelForMaskedLM.from_pretrained(model_checkpoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = model_checkpoint.split(\"/\")[-1]\n",
    "training_args = TrainingArguments(\n",
    "    f\"{model_name}-finetuned-wikitext2\",\n",
    "    evaluation_strategy = \"epoch\",\n",
    "    learning_rate=2e-5,\n",
    "    weight_decay=0.01,\n",
    "    push_to_hub=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import DataCollatorForLanguageModeling\n",
    "data_collator = DataCollatorForLanguageModeling(tokenizer=tokenizer, mlm_probability=0.15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 220/220 [13:29<00:00,  3.68s/it]\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "eval_results = trainer.evaluate()\n",
    "print(f\"Perplexity: {math.exp(eval_results['eval_loss']):.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Upload file pytorch_model.bin: 488MB [05:42, 2.03MB/s]                            To https://huggingface.co/yeseok/gpt2-finetuned-wikitext2\n",
      "   29c6780..eb2f544  main -> main\n",
      "\n",
      "Upload file pytorch_model.bin: 100%|██████████| 475M/475M [05:43<00:00, 1.45MB/s]\n",
      "To https://huggingface.co/yeseok/gpt2-finetuned-wikitext2\n",
      "   eb2f544..df116bc  main -> main\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Save Fine-tuned \n",
    "trainer.save_model('../data/fine_tuned_1201')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.push_to_hub()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda",
   "language": "python",
   "name": "conda"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
